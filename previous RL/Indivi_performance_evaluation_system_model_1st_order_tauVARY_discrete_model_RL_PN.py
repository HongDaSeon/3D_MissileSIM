#!/usr/bin/env python
# coding: utf-8
################################################################################################################################################################################ -ohh`  #####################                
#                                                                                                                                                                             -ohNMMMMd`                    #
#                                                                                                                                                                         -ohNMMMMMmMMMd`                   #
#                                                                                                                                                                     -ohNMMMMNho-  yMMMd`                  #
#                                                                                                                                                                 -ohNMMMMNho-       yMMMd`                 #
#                                                                                                                                                             -ohNMMMMNho-            yMMMd`                #
#                                                                                                                                                         -+hNMMMMMdo-                 yMMMd`               #
#                                                                                                                                                     -+hNMMMMMdo:`                     yMMMd`              #
#                                                                                                                                                 -+hNMMMMMho-                           sMMMd`             #
#                                                                                                                                                `dMMMMho-                                sMMMd`            #
#                                                                                                                                                 `dMMMo                                   sMMMd`           #
#                                                                                                                                                  `dMMMs                                   sMMMd`          #
#                                                                                                                                                   `dMMMs                                   sMMMm`         #
#                                                                                                                                                    `dMMMo         `:osyyo/.                 sMMMm`        #
#                                                                                                                                                     `dMMMo      `sNMMMMMMMMh-                sMMMm`       #
#    MMMMMMMMo mMMMMNNds-    -yNMMMMNd-      sMMs                -MMh                                    `ddh                                          `dMMMo    `mMMMMMMMMMMMM/                sMMMm`      #
#    MMM/----. mMMo--+mMMy  oMMN+.`./h:      sMMy      -+osso/.  -MMh-+so:    :osso/`  .++:`/+`-+osso/. `+MMN++/  -+sso/.  `++/`:+/++-   :++.           `dMMMo   oMMMMMMMMMMMMMm                 sMMMm.     #
#    MMMyssss` mMM/   `mMM/.MMM-             sMMy      oysosmMM/ -MMNhydMMy -mMNsodMN/ /MMNMNN.oysosmMM/.yMMMyyo`dMMyohMMo .MMNNNN+NMN. -MMd             `dMMMs  oMMMMMMMMMMMMMm              ./ymMMMMm`    #
#    MMMhyyyy` mMM/    dMMo-MMM`             sMMy      .+syhmMMs -MMh   NMM.hMM/  `MMM`/MMh    .+syhmMMs `MMN   sMMo   mMM-.MMm`   :MMh dMN.              `dMMMs `mMMMMMMMMMMMM:          `/ymMMMMMms/`     #
#    MMM.      mMM/  `oMMm` mMMy`    /.      sMMy     :MMd:-oMMs -MMh  `NMM`hMM/  `MMN`/MMy   :MMd:-oMMs `MMN   oMMs   mMM-.MMm     oMMdMM:                `dMMMs `sNMMMMMMMMh-       `/smMMMMMms/`         #
#    MMM.      mMMmdmMMNs`  `yMMNdhdNM:      sMMNmmmmd-MMNssmMMs -MMNyyNMN/ .mMNysmMN/ /MMy   -MMNssmMMs  mMMhss`hMMysdMMo .MMm      hMMMs                  `dMMMs   -+ssso/`     `/smMMMMMms/`             #
#    ///`      //////:.       `:+oo+:.       -//////// .+o+:.//- `//::++/`    -+oo+:`  .//-    .+o+:.//-   :+o+:  ./ooo/`  `///      +MMd                    `dMMMs           ./smMMMMMms/`                 #
#                                                                                                                                   .NMN.                     `dMMMs      ./ymMMMMMms/`                     #
#                                                                                                                                   `..`                       `hMMMs `/smMMMMMmy/`                         #
#                                                                                                                                                               `hMMMmMMMMMmy/.                             #
#                                             T  H  E    M  O  T  I  O  N    T  E  C  H  N  O  L  O  G  Y    I  N  N  O  V  A  T  I  O  N  S                     `hMMMMmy/.                                 #
#                                                                                                                                                                 `yy/.                                     #
#                                                                                                                                                                                                           #
#   ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  #
#                                                                                                                                                                                                           #
#                    `++++++/-`    `+++++++-   -+ooo+:  .++.     ./oooo+-   +++`     :+/   +++++++-  -++++++++++++//:.                                                                                      #
#                    .MMmyyhmMMh-  `MMmyyyy: -mMmsosyy  /MM:   +mMmyssydh   MMMN:    hMm   NMmyyyy/  oMMMMMMMMMMMMMMMMMmy+.                                                                                 #
#                    .MMo    -mMN. `MMo      sMM/       /MM:  hMN/          MMhNMo   hMm   NMy       oMMMMMMMMMMMMMMMMMMMMMh:                                                                               #
#                    .MMo     :MMo `MMmyyyy` `yMMmy+.   /MM: :MMo  `+++++.  MMs.dMh` hMm   NMmyyyy.  oMMMMM+     `.:odMMMMMMMy                                                                              #
#                    .MMo     /MM+ `MMh++++`   `:sdMMy  /MM: :MMo  `yydMM:  MMs  sMm-hMm   NMd++++`  oMMMMM+          .yMMMMMMy                                                                             #
#                    .MMo   `+NMh  `MMo      .     sMM: /MM:  dMN/    /MM:  MMs   /NMmMm   NMy       oMMMMM+            +MMMMMM:                                                                            #
#                    .MMNddmMMh/   `MMNdddds sNdyydMMy  /MM:  `omMNdhhNMM-  MMs    .dMMm   NMNddddy  oMMMMM+             hMMMMMy                                                                            #
#                     :::::-.       :::::::- `-////-`   `::`     .:///:-`   ::.      ::-   :::::::-  oMMMMM+             +MMMMMm                                                                            #
#                                                                                                    oMMMMM+             +MMMMMd                                                                            #
#                                                                                .-`                 oMMMMM+             hMMMMMs                                                                            #
#                                                                                dM:                 oMMMMM+            /MMMMMM. `mmm.    /hmmmm+ `mmmmmm`  /hmNNmy:   dmd.   -mh                           #
#                                                                                dM:-//- `//`  `/:   oMMMMM+          `oMMMMMM/  hMoMd   -MM.   ` `MM`    `dMs.  -hMy  mMmN/  :Md                           #
#                                                                                dMdo+hMy sMs  yM/   oMMMMM+       `:sNMMMMMm:  oMs yMo   sNNh+.  `MMysso +Mm     .MM. mM-sMs :Md                           #
#                                                                                dM:  `MM` dM::Ms    oMMMMMmhhhhddNMMMMMMMNo`  :MMssyMM:    -omMy `MM:::- /MN`    -MM` mM- :Nd/Md                           #
#                                                                                dMy..sMd  `mmNd     oMMMMMMMMMMMMMMMMMmy:    `NM+:::+MN`-+-.-sMm `MM/:::` yMd+::oNN/  mM-  .dMMd                           #
#                                                                                os/shy/    :MN.     /hhhhhhhhhhhyso+:`       /s+     +s/.syhys+` `ssssss-  .+yhys/`   os.    oso                           #
#                                                                                         /+mN-                                                                                                             #
######################################################################################## /+:` ###############################################################################################################
# Missile_Reinforcement_Learning_platform
#    v-run the trained network
# In[1]:


import vpython as vp
import Missile_ENV_V_3_Ldot_Vm_ideal as MissSim
import math as m
import csv
import sys
import numpy as np
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.distributions import Normal
import torchvision.transforms as transforms
import time
import copy
import pickle
from collections import namedtuple
import matplotlib.pyplot as plt
import numpy as np
import random as rd
import control.matlab as ctr

# system param
time_const = [0,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.75,1]

a_render = True
#basic initialization+++++++++++++++++++++++++++++++++++++++++++++
slept = False
animcounter = 0
#lr = 1e-4
# nn param
gpu_num = 1
mu_now = 0
hitCount = 0

init_data_set = np.zeros([100,4])

Target_x = 0
Target_y = 0
# sophnorm_weight to acc / 1174 is optimal til now
# 
file_dir = 'sophnorm_acc_weight'
weight_num = 17704
actor_weightfile = 'params/anet_params_R,initL,Ohm'+str(weight_num)+'.pkl'
criti_weightfile = 'param/solved/ddpg_cnet_params_7.pkl'
# In[3]:
device = ('cuda'+':'+ str(gpu_num)) if torch.cuda.is_available() else 'cpu'

a_seed = 0
#a_gamma = 0.9
max_step_count = 600

a_log_interval = 10
torch.manual_seed(a_seed)
np.random.seed(a_seed)
if device == ('cuda'+ ':' + str(gpu_num)) :
    torch.cuda.manual_seed_all(a_seed)

TrainingRecord = namedtuple('TrainingRecord', ['ep', 'reward'])
Transition = namedtuple('Transition', ['s', 'a', 'r', 's_'])

print(device)

# In[4]:

wide_scale = 2

class ActorNet(nn.Module):

    def __init__(self):
        super(ActorNet, self).__init__()
        self.fc     = nn.Linear(2, 400)
        self.hd     = nn.Linear(400, 600)
        self.hd2     = nn.Linear(600, 400)
        self.mu_layer = nn.Linear(400, 1)
        
        torch.nn.init.xavier_uniform_(self.fc.weight)
        torch.nn.init.xavier_uniform_(self.hd.weight)   
        torch.nn.init.xavier_uniform_(self.hd2.weight)  
        torch.nn.init.xavier_uniform_(self.mu_layer.weight)

    def forward(self, s):
        s   = torch.tensor(s, dtype=torch.float)
        s   = s.to(device)
        x   = (self.fc(s))
        x   = torch.tanh(self.hd(x))
        x   = torch.tanh(self.hd2(x))
        acc = self.mu_layer(x) #2 .0 * F.tanh(self.mu_layer(x))
        acc = acc.to('cpu')
        return acc

class CriticNet(nn.Module):

    def __init__(self):
        super(CriticNet, self).__init__()
        self.fc = nn.Linear(4, 200*wide_scale)
        self.hd = nn.Linear(200*wide_scale, 300*wide_scale)
        self.hd2 = nn.Linear(300*wide_scale, 200*wide_scale)
        self.Q_layer = nn.Linear(200*wide_scale, 1)
        
        torch.nn.init.xavier_uniform_(self.fc.weight)
        torch.nn.init.xavier_uniform_(self.hd.weight)
        torch.nn.init.xavier_uniform_(self.hd2.weight)
        torch.nn.init.xavier_uniform_(self.Q_layer.weight)

    def forward(self, s, a):
        s   = s.to(device)
        a   = a.to(device)
        x = self.fc(torch.cat([s, a], dim=1))
        x = torch.tanh(self.hd(x))
        x = torch.tanh(self.hd2(x))
        state_value = self.Q_layer(x)
        state_value = state_value.to('cpu')
        return state_value

class ControllerSim:
    def __init__(self, tau, dt):
        self.tau = tau
        self.dt = dt
        self.prev_am = 0
        
    def reset(self):
        self.prev_am = 0
        
    def sim(self, cmd):
        amt = ( ( cmd + ( self.tau * self.prev_am / self.dt ) ) / ( 1 + self.tau/self.dt ) )
        self.prev_am = amt
        return amt
    
# In[6]:
# Model initialization _++++++++++++++++++++++++++++++++++
print('processing')
print('device : '+str(device))
ac_model    = ActorNet().to(device)
print('pass1')
ac_loaded   = torch.load( actor_weightfile, map_location= device )
print('pass1.5')
ac_model.load_state_dict(ac_loaded)
ac_model.float()
print('pass2')
ac_model.eval()
print('Good2Go')

def init_picker(case):
    
    initR   = init_data_set[case,0]
    initlam = init_data_set[case,1] 
    initpsi = init_data_set[case,2]
    initVm  = init_data_set[case,3]

    x__pos_rand = initR*m.cos(initlam-m.pi)
    y__pos_rand = initR*m.sin(initlam-m.pi)
    headin_rand = initpsi

    print(str(x__pos_rand)+','+str(y__pos_rand))

    return x__pos_rand, y__pos_rand, headin_rand, initVm

def addNoise(sacrifice, aver, var):
    return sacrifice + np.random.normal( aver, var)

PNGLdot = []

def PNG(L__dotb, V__m):
    global PNGLdot
    ay = (2 * L__dotb*V__m)
    #print(ay)
    PNGLdot.append(L__dotb)
    return ay

def write_CSV(chunk, ep, tc, override = 'none'):
    global spamwriter
    if override == 'none' :
        with open('intellectual_Utility_now_N2'+str(weight_num)+'_tau'+str(tc)+'.csv', 'a', newline='') as csvfile:
            spamwriter = csv.writer(csvfile, delimiter=',')
            spamwriter.writerow(chunk)
    else:
        with open('intellectual_Utility_now_N2'+str(weight_num)+'_tau'+str(tc)+'.csv', 'a', newline='') as csvfile:
            spamwriter = csv.writer(csvfile, delimiter=',')
            spamwriter.writerow(override)

def read_CSV():
    global init_data_set
    count_row = 0
    with open('testset_init_final.csv', newline='') as f:
        reader = csv.reader(f)
        for row in reader:
            init_data_set[count_row] = row
            count_row += 1
    print(init_data_set)

if a_render:
    scene1 = vp.canvas(title = "close_look",
                    x=0,y=0, width=500, height=300,
                    range=10, background=vp.color.black,
                    center = vp.vec(10,10,0))
    g1 = vp.graph(title = "LOS",width = 500, height = 200)
    g2 = vp.graph(title = "R", width = 500, height = 200)
    g3 = vp.graph(title = "acc", width = 500, height = 200)
    g4 = vp.graph(title = "reward", width = 500, height = 200)
    g5 = vp.graph(title = "training_status", width = 500, height = 500)
    g6 = vp.graph(title = "trajectory\n("+str(Target_x)+','+str(Target_y)+')', width = 500, height = 500, xmin = -50000, xmax = 50000, ymin = -50000, ymax = 50000)

# In[7]:


#Params
Vm = 250
initpos = [0., 0.]
initpsi = 0.
dt = 0.1 ##sec
animspeed = 400
animdt = dt / animspeed


# In[8]:

def mronV(normV):
    return normV*200 + 400

def mronLd(normLd):
    return normLd/1000


# Generate Model Objects
missile_model_1 = MissSim.Missile_2D(Vm, initpos[0], initpos[1], initpsi, dt)
print(missile_model_1)
target_model_1  = MissSim.TargetShip(0,0,0,0)
print(target_model_1)
seeker_model_1  = MissSim.Seeker(missile_model_1, target_model_1)


# Plots initializtion
if a_render:
    LOS_graph   = vp.gcurve(graph = g1, color = vp.color.cyan)
    fLOS_graph  = vp.gcurve(graph = g1, color = vp.color.blue)
    R_graph     = vp.gcurve(graph = g2, color = vp.color.magenta)
    acc_graph   = vp.gcurve(graph = g3, color = vp.color.black)
    mu_graph    = vp.gcurve(graph = g3, color = vp.color.red)
    rew_graph   = vp.gcurve(graph = g4, color = vp.color.blue)
    stt_graph   = vp.gcurve(graph = g5, color = vp.color.green)
    trajectory  = vp.gdots(graph = g6, color = vp.vec(rd.random(),rd.random(),rd.random()), radius = 0.2)
    missile_visual = vp.sphere(axis = missile_model_1.vizvel, size = vp.vec(2.01,0.5,0.5), color = vp.color.red,
                            accaxis = missile_model_1.accaxi, make_trail = True, retain = 600)
    target_visual  = vp.box(length = 50, width = 15, height = 15, pos = target_model_1.vizpos)

    missile_visual.pos = missile_model_1.vizpos
    missile_visual.v   = missile_model_1.vizvel

#vp.attach_trail(missile_visual, retain = 600)

#agent = Agent()

noise_switch = False

training_records = []

running_reward, running_q = -1000, 0
with torch.no_grad():
    
    read_CSV()
    for tcon in time_const:
        write_CSV([0], 1, tcon, ['Rf_RL','Energy_RL','Rf_PN','Energy_PN'])
        Dmodel = ControllerSim(tcon,dt)
        for i_ep in range(100):
            print('=================================================================================')
            RLR = 0
            RLenergy = 0
            PNR = 0
            PNenergy = 0
            energy_term = []
            t = 0 ##sec
            score = 0
            xpos, ypos, hed, Vm = init_picker(i_ep)
            print('EP : ', i_ep, '| Init : ', xpos, ypos, hed, Vm)
            Dmodel.reset() # Dynamic model reset
            missile_model_1.reset(xpos, ypos, hed, Vm, reset_flag = True)
            seeker_model_1.impactR = 50000
            _, initLOS, _, _, _, state = seeker_model_1.seek()
            closestR = 999999
            if a_render:
                trajectory  = vp.gdots(graph = g6, color = vp.vec(rd.random(),rd.random(),rd.random()), radius = 0.5)
            step_count = 0
            energy = 0
           
            # ===== NN ======
            print('------------------------NN-------------------------------------------------------')
            while t<max_step_count:
                if a_render : 
                    vp.rate(1/animdt)
                    pass

                action = [np.clip(ac_model(state)[0],-99, 99)]

                model_action = Dmodel.sim(action[0]) # controller model

                missile_model_1.simulate([model_action])
                
                R_mez, LOS, _, lpfLOS, _, state_ = seeker_model_1.seek()
                reward, s_reward, done, is_hit = seeker_model_1.spit_reward(action)
                energy_term.append(reward.item())

                if t == max_step_count-1:
                    done = True
                if done:
                    pass
                if done:
                    hitCount += 1
                    RLR = s_reward
                    for r in energy_term : energy += r*dt
                    RLenergy = energy
                    print('NN_done!!!+++++, | impactR :', seeker_model_1.impactR, '| Energy : ', energy)
                    #lr = lr

                score += reward
                if a_render:

                    LOS_graph.plot(t,LOS)
                    fLOS_graph.plot(t,lpfLOS)
                    R_graph.plot(t,R_mez)
                    acc_graph.plot(t,action[0])
                    mu_graph.plot(t,mu_now)
                    rew_graph.plot(t,reward)
                    missile_visual.pos  = missile_model_1.vizpos
                    missile_visual.axis = missile_model_1.vizvel
                    if step_count==20:
                        trajectory.plot(missile_visual.pos.x, missile_visual.pos.y)
                        step_count = 0
                        scene1.center = missile_visual.pos
                #agent.store_transition(Transition(state, action, (reward + 8) / 8, state_))
                step_count += 1
                state = state_
                if closestR > R_mez:
                    closestR = R_mez
                t = t + dt
                if done:
                    break
            
            '''
            plt.plot(ddpg_time, ddpg_acc)
            plt.title('DDPG')
            plt.xlabel('time[sec]')
            plt.ylabel('acc[m/s2')
            '''

            plt.show()
            # PNG part++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++



            #xpos, ypos, hed = init_picker()
            print('-----------------------PNG-------------------------------------------------------')
            Dmodel.reset()
            missile_model_1.reset(xpos, ypos, hed, Vm, reset_flag = True)
            t = 0 ##sec
            step_count = 0
            seeker_model_1.impactR = 50000
            _, LOS, RLdot, _, _, state = seeker_model_1.seek()
            energy_term = []
            energy = 0
            pngtime = []
            pngacc  = []
            while t<max_step_count:
                if a_render : 
                    vp.rate(1/animdt)
                    
                Ldot_state = mronLd(state[0])
                Vm_state = mronV(state[1])
                
                action = [np.clip(PNG(Ldot_state, Vm_state),-99, 99)]


                model_action = Dmodel.sim(action[0])

                missile_model_1.simulate([model_action])
                
                #print(RLdot, action[0], missile_model_1.psi)
                R_mez, LOS, RLdot, lpfLOS, _, state_ = seeker_model_1.seek()

                reward, s_reward, done, is_hit = seeker_model_1.spit_reward(action)
                energy_term.append(reward.item())
                if t == max_step_count-1:
                    done = True
                if done:
                    pass
                if done:

                    hitCount += 1
                    PNR = s_reward
                    for r in energy_term : energy += r*dt
                    PNenergy = energy
                    print('PNG_done!!!++++, | impactR :', seeker_model_1.impactR, '| Energy : ', energy)
                    #lr = lr/2

                score += reward
                if a_render:
                    LOS_graph.plot(t,LOS)
                    fLOS_graph.plot(t,lpfLOS)
                    R_graph.plot(t,R_mez)
                    acc_graph.plot(t,action[0])
                    mu_graph.plot(t,mu_now)
                    rew_graph.plot(t,reward)
                    missile_visual.pos  = missile_model_1.vizpos
                    missile_visual.axis = missile_model_1.vizvel
                    if step_count==40:
                        trajectory.plot(missile_visual.pos.x, missile_visual.pos.y)
                        step_count = 0
                        scene1.center = missile_visual.pos
                #agent.store_transition(Transition(state, action, (reward + 8) / 8, state_))
                step_count += 1
                state = state_
                if closestR > R_mez:
                    closestR = R_mez
                t = t + dt
                if done:
                    break
            write_CSV([RLR, RLenergy, PNR, PNenergy], 1, tcon)
            '''    
            plt.plot(pngtime, pngacc)
            plt.title('PNG')
            plt.xlabel('time[sec]')
            plt.ylabel('acc[m/s2')
            plt.show()

            plt.figure()
            plt.plot(pngtime, PNGLdot)
            plt.title('PNG')
            plt.xlabel('time[sec]')
            plt.ylabel('losdot')
            plt.show()
            '''
            seeker_model_1.filter1st = True
            # print(closestR)
            if a_render:
                stt_graph.plot(i_ep,closestR)    
                if i_ep % 2 == 0 :
                    #print(i_ep)
                    LOS_graph.delete()
                    fLOS_graph.delete()
                    R_graph.delete()
                    acc_graph.delete()
                    rew_graph.delete()
                    mu_graph.delete()
                
            running_reward = running_reward * 0.9 + score * 0.1

            #print(i_ep, running_reward, running_q)
            #print('Step {}\tAverage score: {:.2f}\tAverage Q: {:.2f}'.format(
            #    i_ep, running_reward, running_q))
            print('=================================================================================\n\n')
            
#env.close()

#plt.plot([r.ep for r in training_records], [r.reward for r in training_records])
#plt.title('DDPG')
#plt.xlabel('Episode')
#plt.ylabel('Moving averaged episode reward')
#plt.savefig("img/ddpg.png")
#plt.show()
